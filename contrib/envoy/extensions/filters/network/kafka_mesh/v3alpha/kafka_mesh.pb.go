// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v5.29.3
// source: contrib/envoy/extensions/filters/network/kafka_mesh/v3alpha/kafka_mesh.proto

package v3alpha

import (
	_ "github.com/cncf/xds/go/udpa/annotations"
	_ "github.com/cncf/xds/go/xds/annotations/v3"
	_ "github.com/envoyproxy/protoc-gen-validate/validate"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type KafkaMesh_ConsumerProxyMode int32

const (
	// Records received are going to be distributed amongst downstream consumer connections.
	// In this mode Envoy uses librdkafka consumers pointing at upstream Kafka clusters, what means that these
	// consumers' position is meaningful and affects what records are received from upstream.
	// Users might want to take a look into these consumers' custom configuration to manage their auto-committing
	// capabilities, as it will impact Envoy's behaviour in case of restarts.
	KafkaMesh_StatefulConsumerProxy KafkaMesh_ConsumerProxyMode = 0
)

// Enum value maps for KafkaMesh_ConsumerProxyMode.
var (
	KafkaMesh_ConsumerProxyMode_name = map[int32]string{
		0: "StatefulConsumerProxy",
	}
	KafkaMesh_ConsumerProxyMode_value = map[string]int32{
		"StatefulConsumerProxy": 0,
	}
)

func (x KafkaMesh_ConsumerProxyMode) Enum() *KafkaMesh_ConsumerProxyMode {
	p := new(KafkaMesh_ConsumerProxyMode)
	*p = x
	return p
}

func (x KafkaMesh_ConsumerProxyMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (KafkaMesh_ConsumerProxyMode) Descriptor() protoreflect.EnumDescriptor {
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_enumTypes[0].Descriptor()
}

func (KafkaMesh_ConsumerProxyMode) Type() protoreflect.EnumType {
	return &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_enumTypes[0]
}

func (x KafkaMesh_ConsumerProxyMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use KafkaMesh_ConsumerProxyMode.Descriptor instead.
func (KafkaMesh_ConsumerProxyMode) EnumDescriptor() ([]byte, []int) {
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescGZIP(), []int{0, 0}
}

// [#next-free-field: 6]
type KafkaMesh struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Envoy's host that's advertised to clients.
	// Has the same meaning as corresponding Kafka broker properties.
	// Usually equal to filter chain's listener config, but needs to be reachable by clients
	// (so 0.0.0.0 will not work).
	AdvertisedHost string `protobuf:"bytes,1,opt,name=advertised_host,json=advertisedHost,proto3" json:"advertised_host,omitempty"`
	// Envoy's port that's advertised to clients.
	AdvertisedPort int32 `protobuf:"varint,2,opt,name=advertised_port,json=advertisedPort,proto3" json:"advertised_port,omitempty"`
	// Upstream clusters this filter will connect to.
	UpstreamClusters []*KafkaClusterDefinition `protobuf:"bytes,3,rep,name=upstream_clusters,json=upstreamClusters,proto3" json:"upstream_clusters,omitempty"`
	// Rules that will decide which cluster gets which request.
	ForwardingRules []*ForwardingRule `protobuf:"bytes,4,rep,name=forwarding_rules,json=forwardingRules,proto3" json:"forwarding_rules,omitempty"`
	// How the consumer proxying should behave - this relates mostly to Fetch request handling.
	ConsumerProxyMode KafkaMesh_ConsumerProxyMode `protobuf:"varint,5,opt,name=consumer_proxy_mode,json=consumerProxyMode,proto3,enum=envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh_ConsumerProxyMode" json:"consumer_proxy_mode,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *KafkaMesh) Reset() {
	*x = KafkaMesh{}
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaMesh) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaMesh) ProtoMessage() {}

func (x *KafkaMesh) ProtoReflect() protoreflect.Message {
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaMesh.ProtoReflect.Descriptor instead.
func (*KafkaMesh) Descriptor() ([]byte, []int) {
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescGZIP(), []int{0}
}

func (x *KafkaMesh) GetAdvertisedHost() string {
	if x != nil {
		return x.AdvertisedHost
	}
	return ""
}

func (x *KafkaMesh) GetAdvertisedPort() int32 {
	if x != nil {
		return x.AdvertisedPort
	}
	return 0
}

func (x *KafkaMesh) GetUpstreamClusters() []*KafkaClusterDefinition {
	if x != nil {
		return x.UpstreamClusters
	}
	return nil
}

func (x *KafkaMesh) GetForwardingRules() []*ForwardingRule {
	if x != nil {
		return x.ForwardingRules
	}
	return nil
}

func (x *KafkaMesh) GetConsumerProxyMode() KafkaMesh_ConsumerProxyMode {
	if x != nil {
		return x.ConsumerProxyMode
	}
	return KafkaMesh_StatefulConsumerProxy
}

// [#next-free-field: 6]
type KafkaClusterDefinition struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Cluster name.
	ClusterName string `protobuf:"bytes,1,opt,name=cluster_name,json=clusterName,proto3" json:"cluster_name,omitempty"`
	// Kafka cluster address.
	BootstrapServers string `protobuf:"bytes,2,opt,name=bootstrap_servers,json=bootstrapServers,proto3" json:"bootstrap_servers,omitempty"`
	// Default number of partitions present in this cluster.
	// This is especially important for clients that do not specify partition in their payloads and depend on this value for hashing.
	// The same number of partitions is going to be used by upstream-pointing Kafka consumers for consumer proxying scenarios.
	PartitionCount int32 `protobuf:"varint,3,opt,name=partition_count,json=partitionCount,proto3" json:"partition_count,omitempty"`
	// Custom configuration passed to Kafka producer.
	ProducerConfig map[string]string `protobuf:"bytes,4,rep,name=producer_config,json=producerConfig,proto3" json:"producer_config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Custom configuration passed to Kafka consumer.
	ConsumerConfig map[string]string `protobuf:"bytes,5,rep,name=consumer_config,json=consumerConfig,proto3" json:"consumer_config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *KafkaClusterDefinition) Reset() {
	*x = KafkaClusterDefinition{}
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaClusterDefinition) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaClusterDefinition) ProtoMessage() {}

func (x *KafkaClusterDefinition) ProtoReflect() protoreflect.Message {
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaClusterDefinition.ProtoReflect.Descriptor instead.
func (*KafkaClusterDefinition) Descriptor() ([]byte, []int) {
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescGZIP(), []int{1}
}

func (x *KafkaClusterDefinition) GetClusterName() string {
	if x != nil {
		return x.ClusterName
	}
	return ""
}

func (x *KafkaClusterDefinition) GetBootstrapServers() string {
	if x != nil {
		return x.BootstrapServers
	}
	return ""
}

func (x *KafkaClusterDefinition) GetPartitionCount() int32 {
	if x != nil {
		return x.PartitionCount
	}
	return 0
}

func (x *KafkaClusterDefinition) GetProducerConfig() map[string]string {
	if x != nil {
		return x.ProducerConfig
	}
	return nil
}

func (x *KafkaClusterDefinition) GetConsumerConfig() map[string]string {
	if x != nil {
		return x.ConsumerConfig
	}
	return nil
}

type ForwardingRule struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Cluster name.
	TargetCluster string `protobuf:"bytes,1,opt,name=target_cluster,json=targetCluster,proto3" json:"target_cluster,omitempty"`
	// Types that are valid to be assigned to Trigger:
	//
	//	*ForwardingRule_TopicPrefix
	Trigger       isForwardingRule_Trigger `protobuf_oneof:"trigger"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ForwardingRule) Reset() {
	*x = ForwardingRule{}
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ForwardingRule) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ForwardingRule) ProtoMessage() {}

func (x *ForwardingRule) ProtoReflect() protoreflect.Message {
	mi := &file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ForwardingRule.ProtoReflect.Descriptor instead.
func (*ForwardingRule) Descriptor() ([]byte, []int) {
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescGZIP(), []int{2}
}

func (x *ForwardingRule) GetTargetCluster() string {
	if x != nil {
		return x.TargetCluster
	}
	return ""
}

func (x *ForwardingRule) GetTrigger() isForwardingRule_Trigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *ForwardingRule) GetTopicPrefix() string {
	if x != nil {
		if x, ok := x.Trigger.(*ForwardingRule_TopicPrefix); ok {
			return x.TopicPrefix
		}
	}
	return ""
}

type isForwardingRule_Trigger interface {
	isForwardingRule_Trigger()
}

type ForwardingRule_TopicPrefix struct {
	// Intended place for future types of forwarding rules.
	TopicPrefix string `protobuf:"bytes,2,opt,name=topic_prefix,json=topicPrefix,proto3,oneof"`
}

func (*ForwardingRule_TopicPrefix) isForwardingRule_Trigger() {}

var File_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto protoreflect.FileDescriptor

const file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDesc = "" +
	"\n" +
	"Lcontrib/envoy/extensions/filters/network/kafka_mesh/v3alpha/kafka_mesh.proto\x123envoy.extensions.filters.network.kafka_mesh.v3alpha\x1a\x1fxds/annotations/v3/status.proto\x1a\x1dudpa/annotations/status.proto\x1a\x17validate/validate.proto\"\x8c\x04\n" +
	"\tKafkaMesh\x120\n" +
	"\x0fadvertised_host\x18\x01 \x01(\tB\a\xfaB\x04r\x02\x10\x01R\x0eadvertisedHost\x120\n" +
	"\x0fadvertised_port\x18\x02 \x01(\x05B\a\xfaB\x04\x1a\x02 \x00R\x0eadvertisedPort\x12x\n" +
	"\x11upstream_clusters\x18\x03 \x03(\v2K.envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinitionR\x10upstreamClusters\x12n\n" +
	"\x10forwarding_rules\x18\x04 \x03(\v2C.envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRuleR\x0fforwardingRules\x12\x80\x01\n" +
	"\x13consumer_proxy_mode\x18\x05 \x01(\x0e2P.envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyModeR\x11consumerProxyMode\".\n" +
	"\x11ConsumerProxyMode\x12\x19\n" +
	"\x15StatefulConsumerProxy\x10\x00\"\xc8\x04\n" +
	"\x16KafkaClusterDefinition\x12*\n" +
	"\fcluster_name\x18\x01 \x01(\tB\a\xfaB\x04r\x02\x10\x01R\vclusterName\x124\n" +
	"\x11bootstrap_servers\x18\x02 \x01(\tB\a\xfaB\x04r\x02\x10\x01R\x10bootstrapServers\x120\n" +
	"\x0fpartition_count\x18\x03 \x01(\x05B\a\xfaB\x04\x1a\x02 \x00R\x0epartitionCount\x12\x88\x01\n" +
	"\x0fproducer_config\x18\x04 \x03(\v2_.envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ProducerConfigEntryR\x0eproducerConfig\x12\x88\x01\n" +
	"\x0fconsumer_config\x18\x05 \x03(\v2_.envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ConsumerConfigEntryR\x0econsumerConfig\x1aA\n" +
	"\x13ProducerConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1aA\n" +
	"\x13ConsumerConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"g\n" +
	"\x0eForwardingRule\x12%\n" +
	"\x0etarget_cluster\x18\x01 \x01(\tR\rtargetCluster\x12#\n" +
	"\ftopic_prefix\x18\x02 \x01(\tH\x00R\vtopicPrefixB\t\n" +
	"\atriggerB\xc9\x01\xba\x80\xc8\xd1\x06\x02\x10\x02\xd2Æ¤\xe1\x06\x02\b\x01\n" +
	"Aio.envoyproxy.envoy.extensions.filters.network.kafka_mesh.v3alphaB\x0eKafkaMeshProtoP\x01Zbgithub.com/envoyproxy/go-control-plane/contrib/envoy/extensions/filters/network/kafka_mesh/v3alphab\x06proto3"

var (
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescOnce sync.Once
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescData []byte
)

func file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescGZIP() []byte {
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescOnce.Do(func() {
		file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDesc), len(file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDesc)))
	})
	return file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDescData
}

var file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes = make([]protoimpl.MessageInfo, 5)
var file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_goTypes = []any{
	(KafkaMesh_ConsumerProxyMode)(0), // 0: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode
	(*KafkaMesh)(nil),                // 1: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh
	(*KafkaClusterDefinition)(nil),   // 2: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition
	(*ForwardingRule)(nil),           // 3: envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule
	nil,                              // 4: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ProducerConfigEntry
	nil,                              // 5: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ConsumerConfigEntry
}
var file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_depIdxs = []int32{
	2, // 0: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.upstream_clusters:type_name -> envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition
	3, // 1: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.forwarding_rules:type_name -> envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule
	0, // 2: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.consumer_proxy_mode:type_name -> envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode
	4, // 3: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.producer_config:type_name -> envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ProducerConfigEntry
	5, // 4: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.consumer_config:type_name -> envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.ConsumerConfigEntry
	5, // [5:5] is the sub-list for method output_type
	5, // [5:5] is the sub-list for method input_type
	5, // [5:5] is the sub-list for extension type_name
	5, // [5:5] is the sub-list for extension extendee
	0, // [0:5] is the sub-list for field type_name
}

func init() { file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_init() }
func file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_init() {
	if File_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto != nil {
		return
	}
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes[2].OneofWrappers = []any{
		(*ForwardingRule_TopicPrefix)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDesc), len(file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   5,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_goTypes,
		DependencyIndexes: file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_depIdxs,
		EnumInfos:         file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_enumTypes,
		MessageInfos:      file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_msgTypes,
	}.Build()
	File_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto = out.File
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_goTypes = nil
	file_contrib_envoy_extensions_filters_network_kafka_mesh_v3alpha_kafka_mesh_proto_depIdxs = nil
}
